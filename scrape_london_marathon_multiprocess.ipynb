{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import lxml\n",
    "import cchardet\n",
    "import re\n",
    "import concurrent.futures\n",
    "from bs4 import BeautifulSoup, SoupStrainer\n",
    "from multiprocessing import Pool\n",
    "from multiprocessing import cpu_count"
   ]
  },
  {
   "source": [
    "# Function Definitions:\n",
    "Two main functions, get_results old and new. These correspond to the two website styles"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results_new(url, sex, year):\n",
    "    #Function to scrape modern virgin london marathon results page (2020 and 2019)\n",
    "    #Set up empty dataframe for results\n",
    "    results = pd.DataFrame()\n",
    "    \n",
    "    #Use requests to get content from site\n",
    "    site=requests.get(url).content\n",
    "    #Soup strainer restricts content to sped up soup\n",
    "    strainer = SoupStrainer(class_=\"section-main\")\n",
    "    #Parse the html\n",
    "    soup = BeautifulSoup(site,'lxml', parse_only=strainer)\n",
    "    #fields = soup.find(class_='section-main')\n",
    "\n",
    "    #Loop through each row and column to create a list of cells\n",
    "    my_table = []\n",
    "    for row in soup.find_all(class_='list-group-item'):\n",
    "        row_data = []\n",
    "        for cell in row.find_all(class_='list-field'):\n",
    "            row_data.append(cell.text)\n",
    "        \n",
    "        #If the row isn't empty, then create a dict of the row to create datafram from\n",
    "        if(len(row_data) > 0):\n",
    "            data_item = {\"Place (Overall)\": row_data[0],\n",
    "                        \"Place (Gender)\": row_data[1],\n",
    "                        \"Place (Category)\": row_data[2],\n",
    "                        \"Name\": row_data[3],\n",
    "                        \"Sex\": sex,\n",
    "                        \"Club\": row_data[4],\n",
    "                        \"Running Number\": row_data[5],\n",
    "                        \"Category\": row_data[6],\n",
    "                        \"Finish\": row_data[8],\n",
    "                        \"Year\": year\n",
    "            }\n",
    "            my_table.append(data_item)\n",
    "    \n",
    "    #Strip table header\n",
    "    df = pd.DataFrame(my_table).iloc[1:]\n",
    "        \n",
    "    #Append to results\n",
    "    results = results.append(df)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results_old(url, sex, year):\n",
    "    #Function to scrape old virgin london marathon results page (2014 to 2018)\n",
    "    #Set up empty dataframe for results\n",
    "    results = pd.DataFrame()\n",
    "\n",
    "    #Use requests to get content from site\n",
    "    site=requests.get(url).content\n",
    "    #Soup strainer restricts content to sped up soup\n",
    "    strainer = SoupStrainer('tbody')\n",
    "    #Parse the html\n",
    "    soup = BeautifulSoup(site,'lxml', parse_only=strainer)\n",
    "\n",
    "    my_table = []\n",
    "    for row in soup.find_all('tr'):\n",
    "        row_data = []\n",
    "        for cell in row.find_all('td'):\n",
    "            #Check if cell has alt text, if so use that as data\n",
    "            alt_text = cell.find('span')\n",
    "            if alt_text != None:\n",
    "                cell = alt_text['title']\n",
    "            else:\n",
    "                cell = cell.text\n",
    "            row_data.append(cell)\n",
    "            \n",
    "        #If the row isn't empty, then create a dict of the row to create datafram from\n",
    "        if(len(row_data) > 0):\n",
    "            data_item = {\"Place (Overall)\": row_data[0],\n",
    "                            \"Place (Gender)\": row_data[1],\n",
    "                            \"Place (Category)\": row_data[2],\n",
    "                            \"Name\": row_data[3],\n",
    "                            \"Sex\": sex,\n",
    "                            \"Club\": row_data[4],\n",
    "                            \"Running Number\": row_data[5],\n",
    "                            \"Category\": row_data[6],\n",
    "                            \"Finish\": row_data[8],\n",
    "                            \"Year\": year\n",
    "            }\n",
    "            my_table.append(data_item)\n",
    "        # elif(len(row_data) > 0 and year == 2014):\n",
    "        #     data_item = {\"Place (Overall)\": row_data[0],\n",
    "        #                     \"Place (Gender)\": row_data[1],\n",
    "        #                     \"Place (Category)\": row_data[2],\n",
    "        #                     \"Name\": row_data[3],\n",
    "        #                     \"Sex\": sex,\n",
    "        #                     \"Club\": row_data[5],\n",
    "        #                     \"Running Number\": row_data[6],\n",
    "        #                     \"Category\": row_data[7],\n",
    "        #                     \"Finish\": row_data[9],\n",
    "        #                     \"Year\": year\n",
    "        #     }\n",
    "        #     my_table.append(data_item)\n",
    "\n",
    "    #Strip table header\n",
    "    df = pd.DataFrame(my_table)\n",
    "\n",
    "    #Append to results\n",
    "    results = results.append(df)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results(url):\n",
    "    #Function choose what results func to apply\n",
    "    #Used to allow single function for pool.map\n",
    "    #Check what year the url is\n",
    "    year = int(re.search('\\.com\\/(\\d{4})\\/', url).group(1))\n",
    "    sex = re.search('sex%5D=(\\w)', url).group(1)\n",
    "    if year >= 2019:\n",
    "        data = get_results_new(url, sex, year)\n",
    "    elif year >= 2010:\n",
    "        data = get_results_old(url, sex, year)\n",
    "    else:\n",
    "        data = None\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_virgin_urls(sex, pages, year):\n",
    "    # Get a list of urls, this is needed to be used to apply function to to then use multiprocessing\n",
    "    urls = ['NaN'] * pages\n",
    "    if year >= 2019:\n",
    "        for i in range(len(urls)):\n",
    "            urls[i] =  'https://results.virginmoneylondonmarathon.com/' \\\n",
    "                        +str(year) \\\n",
    "                        +'/?page=' \\\n",
    "                        +str(i+1) \\\n",
    "                        +'&event=ALL&num_results=1000&pid=search&pidp=results_nav&search%5Bsex%5D=' \\\n",
    "                        +sex \\\n",
    "                        +'&search%5Bage_class%5D=%25&search%5Bnation%5D=%25&search_sort=name'\n",
    "\n",
    "\n",
    "    elif year >= 2014:\n",
    "        for i in range(len(urls)):\n",
    "            urls[i] = ('https://results.virginmoneylondonmarathon.com/'\n",
    "                        +str(year)\n",
    "                        +'/?page='\n",
    "                        +str(i+1)\n",
    "                        +'&event=MAS&num_results=1000&pid=list&search%5Bage_class%5D=%25&search%5Bsex%5D='\n",
    "                        +sex)\n",
    "\n",
    "    elif year >= 2010:\n",
    "        for i in range(len(urls)):\n",
    "            urls[i] = ('https://results.virginmoneylondonmarathon.com/'\n",
    "                        +str(year)\n",
    "                        +'/index.php?page='\n",
    "                        +str(i+1)\n",
    "                        +'&event=MAS&num_results=1000&pid=search&search%5Bsex%5D='\n",
    "                        +sex)\n",
    "\n",
    "    return urls"
   ]
  },
  {
   "source": [
    "# Time to get to work\n",
    "\n",
    "Use get_virgin_urls with a list of page numbers (need to create loop for that) and a range of years to produce the list of urls that we will iterate over\n",
    "\n",
    "NOTE: Is possible to scrape 2010, but slightly diff. format so need to produce a different function for that."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get no. of pages using technique like\n",
    "#Not kept in/included in functions because requests take forever!\n",
    "# url1 = 'https://results.virginmoneylondonmarathon.com/2020/?page='\n",
    "# url2 = '&event=ALL&num_results=1000&pid=search&pidp=results_nav&search%5Bsex%5D='\n",
    "# url3 = '&search%5Bage_class%5D=%25&search%5Bnation%5D=%25&search_sort=name'\n",
    "\n",
    "# site_m=requests.get(url1+'1'+url2+'M' +url3).text\n",
    "# site_w=requests.get(url1+'1'+url2+'W' +url3).text\n",
    "# soup_m = BeautifulSoup(site_m,'lxml')\n",
    "# soup_w = BeautifulSoup(site_w,'lxml')\n",
    "\n",
    "# m_pages = int(soup_m.find(class_='pages').text[-4:-2])\n",
    "# w_pages = int(soup_w.find(class_='pages').text[-4:-2])\n",
    "# print(m_pages, w_pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = []\n",
    "#Get no. of pages using technique like\n",
    "#Not kept in/included in functions because requests take forever!\n",
    "# site_m=requests.get(url1+'1'+url2+'M').text\n",
    "# site_w=requests.get(url1+'1'+url2+'W').text\n",
    "# soup_m = BeautifulSoup(site_m,'lxml')\n",
    "# soup_w = BeautifulSoup(site_w,'lxml')\n",
    "\n",
    "# m_pages = int(soup_m.find(class_='pages').text[-4:-2])\n",
    "# w_pages = int(soup_w.find(class_='pages').text[-4:-2])\n",
    "# print(m_pages, w_pages)\n",
    "pages_men = [23, 24, 23, 23, 24, 24, 24, 24, 29, 22]\n",
    "pages_women = [13, 14, 13, 14, 15, 16, 16, 17, 21, 22]\n",
    "for i, year in enumerate(range(2011, 2020)):\n",
    "    w_urls = get_virgin_urls('W', pages_women[i], year)\n",
    "    m_urls = get_virgin_urls('M', pages_men[i], year)\n",
    "    urls = urls + m_urls + w_urls"
   ]
  },
  {
   "source": [
    "The following cell uses ```multiprocess.pool``` to divide the work of making requests and parsing between a number of worker processes. This currently doesn't lead to any appreciable improvement in speed, needs further investigation! Possibly need to investigate proper threading.\n",
    "\n",
    "This process requires an iterable and a function to apply it over."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%timeit -n 1 -r 1\n",
    "# #Setup multiprocessing and start scraping!\n",
    "# pool = Pool(8)\n",
    "# #Scrape multiprocessing\n",
    "# data = pool.map(get_results, urls)\n",
    "# #Cleanup after yourself\n",
    "# pool.terminate()\n",
    "# pool.join()"
   ]
  },
  {
   "source": [
    "The following cell does a similar process, but using multithreading instead of multiprocessing."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Trying using multithreading instead of multiprocessing\n",
    "MAX_THREADS = 30\n",
    "threads = min(MAX_THREADS, len(urls))\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=threads) as executor:\n",
    "    data = list(executor.map(get_results, urls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get dataframe from list of df (sep cell to allow for recreation without re-parsing)\n",
    "results = pd.concat(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Some data cleaning\n",
    "#Remove leftover titles\n",
    "results['Club'] = results['Club'].str.replace(\"Club\", \"\", regex=False)\n",
    "results['Running Number'] = results['Running Number'].str.replace(\"Running Number\", \"\", regex=False)\n",
    "results['Running Number'] = results['Running Number'].str.replace(\"Runner Number\", \"\", regex=False)\n",
    "results['Category'] = results['Category'].str.replace(\"Category\", \"\", regex=False)\n",
    "results['Finish'] = results['Finish'].str.replace(\"Finish\", \"\", regex=False)\n",
    "\n",
    "#Extract country groups, like (USA), from Name group\n",
    "results['Country'] = results['Name'].str.extract(r'(\\([A-Z]{3,}\\))')\n",
    "#Remove brackets in country\n",
    "results['Country'] = results['Country'].str.replace(r'\\(|\\)', \"\")\n",
    "#Remove country group from name column\n",
    "results['Name'] = results['Name'].str.replace(r'(\\([A-Z]{3}\\))', \"\")\n",
    "\n",
    "#Split first/lastname into new columns\n",
    "results['Name'] = results['Name'].str.replace(r'(»)', \"\")\n",
    "results['Name'] = results['Name'].str.replace(r'(\\n)', \"\")\n",
    "LastFirst = results['Name'].str.split(pat=\",\", n=1, expand=True) \n",
    "results['FirstName'], results['LastName'] = LastFirst[1], LastFirst[0]\n",
    "#Remove comma from Name column, so that this can be saved as a CSV ----- Must happen after splitting Name into two cols!!\n",
    "results['Name'] = results['Name'].str.replace(r'(\\,)', \"\")\n",
    "#Replace non-standard '–' with NaN for missing vals\n",
    "results = results.replace('–', np.nan)\n",
    "results = results.replace('', np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results =  results.astype({\"Place (Overall)\": 'Int64',\n",
    "                           \"Place (Gender)\": 'Int64',\n",
    "                           \"Place (Category)\": 'Int64',\n",
    "                           \"Name\": str,\n",
    "                           \"Sex\": str,\n",
    "                           \"Club\": str,\n",
    "                           \"Running Number\": 'Int64',\n",
    "                           \"Category\": str,\n",
    "                           \"Year\": 'Int64'})\n",
    "results['Finish'] = pd.to_timedelta(results['Finish'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see what we've got\n",
    "results.info()\n",
    "results.describe()\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And quickly save them in a csv\n",
    "results.to_csv(r'C:\\Users\\michael.walshe\\Documents\\Python Projects\\scrape_london_marathon\\London_Marathon_Big.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Profiling function to find bottlenecks, need to speed up parser more???\n",
    "# url = 'https://results.virginmoneylondonmarathon.com/2019/?page=1&event=ALL&'+ \\\n",
    "#       'num_results=1000&pid=search&pidp=results_nav&search%5Bsex%5D=M&search%5Bage_'+ \\\n",
    "#        'class%5D=%25&search%5Bnation%5D=%25&search_sort=name'\n",
    "\n",
    "# %lprun -f get_results_new get_results_new(url, \"M\", 2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_2015 = results.loc[results['Year'] == 2015]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "    Place (Overall) Place (Gender) Place (Category)                   Name  \\\n",
       "0                 1              1                1           Kimpton Ian    \n",
       "1                 2              2                2          Gilbert John    \n",
       "2                 3              3                3           Scott Aaron    \n",
       "3                 4              4                4         Molyneux Paul    \n",
       "4                 5              5                5        Spencer Stuart    \n",
       "..              ...            ...              ...                    ...   \n",
       "373           37591          14374             8636         Gibson Stacey    \n",
       "374           37592          14375             1002        Rusga Caroline    \n",
       "375           37593          14376             8637            Goff Keren    \n",
       "376             DSQ            DSQ              DSQ           Fooks Kathy    \n",
       "377             DSQ            DSQ              DSQ   Roberts Carole Mary    \n",
       "\n",
       "    Sex                       Club Running Number Category    Finish  Year  \\\n",
       "0     M                   Luton Ac           1147    18-39  02:15:51  2015   \n",
       "1     M                    Kent AC            910    18-39  02:18:12  2015   \n",
       "2     M                   Notts AC           1252    18-39  02:20:45  2015   \n",
       "3     M  Springfield Striders Army            939    18-39  02:21:23  2015   \n",
       "4     M                   Notts AC            841    18-39  02:21:25  2015   \n",
       "..   ..                        ...            ...      ...       ...   ...   \n",
       "373   W        Poplar running club          41600    18-39  08:15:46  2015   \n",
       "374   W                        NaN          43515    50-54  08:16:36  2015   \n",
       "375   W                        NaN          35195    18-39  08:20:50  2015   \n",
       "376   W        Littledown Harriers          27866    55-59       DSQ  2015   \n",
       "377   W                  Mysteruns          29123    60-64       DSQ  2015   \n",
       "\n",
       "    Country      FirstName   LastName  \n",
       "0       GBR           Ian     Kimpton  \n",
       "1       GBR          John     Gilbert  \n",
       "2       GBR         Aaron       Scott  \n",
       "3       GBR          Paul    Molyneux  \n",
       "4       GBR        Stuart     Spencer  \n",
       "..      ...            ...        ...  \n",
       "373     GBR        Stacey      Gibson  \n",
       "374     GBR      Caroline       Rusga  \n",
       "375     GBR         Keren        Goff  \n",
       "376     GBR         Kathy       Fooks  \n",
       "377     GBR   Carole Mary     Roberts  \n",
       "\n",
       "[37599 rows x 13 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Place (Overall)</th>\n      <th>Place (Gender)</th>\n      <th>Place (Category)</th>\n      <th>Name</th>\n      <th>Sex</th>\n      <th>Club</th>\n      <th>Running Number</th>\n      <th>Category</th>\n      <th>Finish</th>\n      <th>Year</th>\n      <th>Country</th>\n      <th>FirstName</th>\n      <th>LastName</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Kimpton Ian</td>\n      <td>M</td>\n      <td>Luton Ac</td>\n      <td>1147</td>\n      <td>18-39</td>\n      <td>02:15:51</td>\n      <td>2015</td>\n      <td>GBR</td>\n      <td>Ian</td>\n      <td>Kimpton</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>Gilbert John</td>\n      <td>M</td>\n      <td>Kent AC</td>\n      <td>910</td>\n      <td>18-39</td>\n      <td>02:18:12</td>\n      <td>2015</td>\n      <td>GBR</td>\n      <td>John</td>\n      <td>Gilbert</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>Scott Aaron</td>\n      <td>M</td>\n      <td>Notts AC</td>\n      <td>1252</td>\n      <td>18-39</td>\n      <td>02:20:45</td>\n      <td>2015</td>\n      <td>GBR</td>\n      <td>Aaron</td>\n      <td>Scott</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>4</td>\n      <td>4</td>\n      <td>Molyneux Paul</td>\n      <td>M</td>\n      <td>Springfield Striders Army</td>\n      <td>939</td>\n      <td>18-39</td>\n      <td>02:21:23</td>\n      <td>2015</td>\n      <td>GBR</td>\n      <td>Paul</td>\n      <td>Molyneux</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>5</td>\n      <td>5</td>\n      <td>Spencer Stuart</td>\n      <td>M</td>\n      <td>Notts AC</td>\n      <td>841</td>\n      <td>18-39</td>\n      <td>02:21:25</td>\n      <td>2015</td>\n      <td>GBR</td>\n      <td>Stuart</td>\n      <td>Spencer</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>373</th>\n      <td>37591</td>\n      <td>14374</td>\n      <td>8636</td>\n      <td>Gibson Stacey</td>\n      <td>W</td>\n      <td>Poplar running club</td>\n      <td>41600</td>\n      <td>18-39</td>\n      <td>08:15:46</td>\n      <td>2015</td>\n      <td>GBR</td>\n      <td>Stacey</td>\n      <td>Gibson</td>\n    </tr>\n    <tr>\n      <th>374</th>\n      <td>37592</td>\n      <td>14375</td>\n      <td>1002</td>\n      <td>Rusga Caroline</td>\n      <td>W</td>\n      <td>NaN</td>\n      <td>43515</td>\n      <td>50-54</td>\n      <td>08:16:36</td>\n      <td>2015</td>\n      <td>GBR</td>\n      <td>Caroline</td>\n      <td>Rusga</td>\n    </tr>\n    <tr>\n      <th>375</th>\n      <td>37593</td>\n      <td>14376</td>\n      <td>8637</td>\n      <td>Goff Keren</td>\n      <td>W</td>\n      <td>NaN</td>\n      <td>35195</td>\n      <td>18-39</td>\n      <td>08:20:50</td>\n      <td>2015</td>\n      <td>GBR</td>\n      <td>Keren</td>\n      <td>Goff</td>\n    </tr>\n    <tr>\n      <th>376</th>\n      <td>DSQ</td>\n      <td>DSQ</td>\n      <td>DSQ</td>\n      <td>Fooks Kathy</td>\n      <td>W</td>\n      <td>Littledown Harriers</td>\n      <td>27866</td>\n      <td>55-59</td>\n      <td>DSQ</td>\n      <td>2015</td>\n      <td>GBR</td>\n      <td>Kathy</td>\n      <td>Fooks</td>\n    </tr>\n    <tr>\n      <th>377</th>\n      <td>DSQ</td>\n      <td>DSQ</td>\n      <td>DSQ</td>\n      <td>Roberts Carole Mary</td>\n      <td>W</td>\n      <td>Mysteruns</td>\n      <td>29123</td>\n      <td>60-64</td>\n      <td>DSQ</td>\n      <td>2015</td>\n      <td>GBR</td>\n      <td>Carole Mary</td>\n      <td>Roberts</td>\n    </tr>\n  </tbody>\n</table>\n<p>37599 rows × 13 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 131
    }
   ],
   "source": [
    "results_2015"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python385jvsc74a57bd00188e1d2bc53a9294aae56bf1ea31698e906b60a882ff91489addc94996f1fb7",
   "display_name": "Python 3.8.5 64-bit ('testenv': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}