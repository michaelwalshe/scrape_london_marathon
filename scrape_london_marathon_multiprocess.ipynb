{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import lxml\n",
    "import cchardet\n",
    "import re\n",
    "import concurrent.futures\n",
    "from bs4 import BeautifulSoup, SoupStrainer\n",
    "from multiprocessing import Pool\n",
    "from multiprocessing import cpu_count"
   ]
  },
  {
   "source": [
    "# Function Definitions:\n",
    "Two main functions, get_results old and new. These correspond to the two website styles"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results_new(url, sex, year):\n",
    "    #Function to scrape modern virgin london marathon results page (2020 and 2019)\n",
    "    #Set up empty dataframe for results\n",
    "    results = pd.DataFrame()\n",
    "    \n",
    "    #Use requests to get content from site\n",
    "    site=requests.get(url).content\n",
    "    #Soup strainer restricts content to sped up soup\n",
    "    strainer = SoupStrainer(class_=\"section-main\")\n",
    "    #Parse the html\n",
    "    soup = BeautifulSoup(site,'lxml', parse_only=strainer)\n",
    "    #fields = soup.find(class_='section-main')\n",
    "\n",
    "    #Loop through each row and column to create a list of cells\n",
    "    my_table = []\n",
    "    for row in soup.find_all(class_='list-group-item'):\n",
    "        row_data = []\n",
    "        for cell in row.find_all(class_='list-field'):\n",
    "            row_data.append(cell.text)\n",
    "        \n",
    "        #If the row isn't empty, then create a dict of the row to create datafram from\n",
    "        if(len(row_data) > 0):\n",
    "            data_item = {\"Place (Overall)\": row_data[0],\n",
    "                        \"Place (Gender)\": row_data[1],\n",
    "                        \"Place (Category)\": row_data[2],\n",
    "                        \"Name\": row_data[3],\n",
    "                        \"Sex\": sex,\n",
    "                        \"Club\": row_data[4],\n",
    "                        \"Running Number\": row_data[5],\n",
    "                        \"Category\": row_data[6],\n",
    "                        \"Finish\": row_data[8],\n",
    "                        \"Year\": year\n",
    "            }\n",
    "            my_table.append(data_item)\n",
    "    \n",
    "    #Strip table header\n",
    "    df = pd.DataFrame(my_table).iloc[1:]\n",
    "        \n",
    "    #Append to results\n",
    "    results = results.append(df)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results_old(url, sex, year):\n",
    "    #Function to scrape old virgin london marathon results page (2014 to 2018)\n",
    "    #Set up empty dataframe for results\n",
    "    results = pd.DataFrame()\n",
    "\n",
    "    #Use requests to get content from site\n",
    "    site=requests.get(url).content\n",
    "    #Soup strainer restricts content to sped up soup\n",
    "    strainer = SoupStrainer('tbody')\n",
    "    #Parse the html\n",
    "    soup = BeautifulSoup(site,'lxml', parse_only=strainer)\n",
    "\n",
    "    my_table = []\n",
    "    for row in soup.find_all('tr'):\n",
    "        row_data = []\n",
    "        for cell in row.find_all('td'):\n",
    "            #Check if cell has alt text, if so use that as data\n",
    "            alt_text = cell.find('span')\n",
    "            if alt_text != None:\n",
    "                cell = alt_text['title']\n",
    "            else:\n",
    "                cell = cell.text\n",
    "            row_data.append(cell)\n",
    "            \n",
    "        #If the row isn't empty, then create a dict of the row to create datafram from\n",
    "        if(len(row_data) > 0 and year != 2014):\n",
    "            data_item = {\"Place (Overall)\": row_data[0],\n",
    "                            \"Place (Gender)\": row_data[1],\n",
    "                            \"Place (Category)\": row_data[2],\n",
    "                            \"Name\": row_data[3],\n",
    "                            \"Sex\": sex,\n",
    "                            \"Club\": row_data[4],\n",
    "                            \"Running Number\": row_data[5],\n",
    "                            \"Category\": row_data[6],\n",
    "                            \"Finish\": row_data[8],\n",
    "                            \"Year\": year\n",
    "            }\n",
    "            my_table.append(data_item)\n",
    "        elif(len(row_data) > 0 and year == 2014):\n",
    "            data_item = {\"Place (Overall)\": row_data[0],\n",
    "                            \"Place (Gender)\": row_data[1],\n",
    "                            \"Place (Category)\": row_data[2],\n",
    "                            \"Name\": row_data[3],\n",
    "                            \"Sex\": sex,\n",
    "                            \"Club\": row_data[5],\n",
    "                            \"Running Number\": row_data[6],\n",
    "                            \"Category\": row_data[7],\n",
    "                            \"Finish\": row_data[9],\n",
    "                            \"Year\": year\n",
    "            }\n",
    "            my_table.append(data_item)\n",
    "\n",
    "    #Strip table header\n",
    "    df = pd.DataFrame(my_table)\n",
    "\n",
    "    #Append to results\n",
    "    results = results.append(df)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results(url):\n",
    "    #Function choose what results func to apply\n",
    "    #Used to allow single function for pool.map\n",
    "    #Check what year the url is\n",
    "    year = int(re.search('\\.com\\/(\\d{4})\\/', url).group(1))\n",
    "    sex = re.search('sex%5D=(\\w)', url).group(1)\n",
    "    if year >= 2019:\n",
    "        data = get_results_new(url, sex, year)\n",
    "    elif year >= 2010:\n",
    "        data = get_results_old(url, sex, year)\n",
    "    else:\n",
    "        data = None\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_virgin_urls(sex, pages, year):\n",
    "    # Get a list of urls, this is needed to be used to apply function to to then use multiprocessing\n",
    "    urls = ['NaN'] * pages\n",
    "    if year >= 2019:\n",
    "        for i in range(len(urls)):\n",
    "            urls[i] =  'https://results.virginmoneylondonmarathon.com/' \\\n",
    "                        +str(year) \\\n",
    "                        +'/?page=' \\\n",
    "                        +str(i+1) \\\n",
    "                        +'&event=ALL&num_results=1000&pid=search&pidp=results_nav&search%5Bsex%5D=' \\\n",
    "                        +sex \\\n",
    "                        +'&search%5Bage_class%5D=%25&search%5Bnation%5D=%25&search_sort=name'\n",
    "\n",
    "\n",
    "    elif year >= 2014:\n",
    "        for i in range(len(urls)):\n",
    "            urls[i] = ('https://results.virginmoneylondonmarathon.com/'\n",
    "                        +str(year)\n",
    "                        +'/?page='\n",
    "                        +str(i+1)\n",
    "                        +'&event=MAS&num_results=1000&pid=list&search%5Bage_class%5D=%25&search%5Bsex%5D='\n",
    "                        +sex)\n",
    "\n",
    "    elif year >= 2010:\n",
    "        for i in range(len(urls)):\n",
    "            urls[i] = ('https://results.virginmoneylondonmarathon.com/'\n",
    "                        +str(year)\n",
    "                        +'/index.php?page='\n",
    "                        +str(i+1)\n",
    "                        +'&event=MAS&num_results=1000&pid=search&search%5Bsex%5D='\n",
    "                        +sex)\n",
    "\n",
    "    return urls"
   ]
  },
  {
   "source": [
    "# Time to get to work\n",
    "\n",
    "Use get_virgin_urls with a list of page numbers (need to create loop for that) and a range of years to produce the list of urls that we will iterate over\n",
    "\n",
    "NOTE: Is possible to scrape 2010, but slightly diff. format so need to produce a different function for that."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = []\n",
    "#Get no. of pages using technique like\n",
    "#Not kept in/included in functions because requests take forever!\n",
    "# site_m=requests.get(url1+'1'+url2+'M').text\n",
    "# site_w=requests.get(url1+'1'+url2+'W').text\n",
    "# soup_m = BeautifulSoup(site_m,'lxml')\n",
    "# soup_w = BeautifulSoup(site_w,'lxml')\n",
    "\n",
    "# m_pages = int(soup_m.find(class_='pages').text[-4:-2])\n",
    "# w_pages = int(soup_w.find(class_='pages').text[-4:-2])\n",
    "# print(m_pages, w_pages)\n",
    "pages_men = [24, 23, 25, 23, 24, 24, 24, 24, 25, 22]\n",
    "pages_women = [14, 13, 13, 14, 15, 16, 16, 17, 18, 22]\n",
    "for i, year in enumerate(range(2011, 2021)):\n",
    "    w_urls = get_virgin_urls('W', pages_women[i], year)\n",
    "    m_urls = get_virgin_urls('M', pages_men[i], year)\n",
    "    new_urls = m_urls + w_urls\n",
    "    urls = urls + new_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = []\n",
    "pages_men = [3] * 10\n",
    "pages_women = [3] * 10\n",
    "for i, year in enumerate(range(2011, 2020)):\n",
    "    w_urls = get_virgin_urls('W', pages_women[i], year)\n",
    "    m_urls = get_virgin_urls('M', pages_men[i], year)\n",
    "    new_urls = m_urls + w_urls\n",
    "    urls = urls + new_urls"
   ]
  },
  {
   "source": [
    "The following cell uses ```multiprocess.pool``` to divide the work of making requests and parsing between a number of worker processes. This currently doesn't lead to any appreciable improvement in speed, needs further investigation! Possibly need to investigate proper threading.\n",
    "\n",
    "This process requires an iterable and a function to apply it over."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%timeit -n 1 -r 1\n",
    "# #Setup multiprocessing and start scraping!\n",
    "# pool = Pool(8)\n",
    "# #Scrape multiprocessing\n",
    "# data = pool.map(get_results, urls)\n",
    "# #Cleanup after yourself\n",
    "# pool.terminate()\n",
    "# pool.join()"
   ]
  },
  {
   "source": [
    "The following cell does a similar process, but using multithreading instead of multiprocessing."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Trying using multithreading instead of multiprocessing\n",
    "MAX_THREADS = 30\n",
    "threads = min(MAX_THREADS, len(urls))\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=threads) as executor:\n",
    "    data = list(executor.map(get_results, urls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get dataframe from list of df (sep cell to allow for recreation without re-parsing)\n",
    "results = pd.concat(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Some data cleaning\n",
    "#Remove leftover titles\n",
    "results['Club'] = results['Club'].str.replace(\"Club\", \"\", regex=False)\n",
    "results['Running Number'] = results['Running Number'].str.replace(\"Running Number\", \"\", regex=False)\n",
    "results['Running Number'] = results['Running Number'].str.replace(\"Runner Number\", \"\", regex=False)\n",
    "results['Category'] = results['Category'].str.replace(\"Category\", \"\", regex=False)\n",
    "results['Finish'] = results['Finish'].str.replace(\"Finish\", \"\", regex=False)\n",
    "\n",
    "#Extract country groups, like (USA), from Name group\n",
    "results['Country'] = results['Name'].str.extract(r'(\\([A-Z]{3,}\\))')\n",
    "#Remove brackets in country\n",
    "results['Country'] = results['Country'].str.replace(r'\\(|\\)', \"\")\n",
    "#Remove country group from name column\n",
    "results['Name'] = results['Name'].str.replace(r'(\\([A-Z]{3}\\))', \"\")\n",
    "\n",
    "#Split first/lastname into new columns\n",
    "results['Name'] = results['Name'].str.replace(r'(»)', \"\")\n",
    "LastFirst = results['Name'].str.split(pat=\",\", n=1, expand=True) \n",
    "results['FirstName'], results['LastName'] = LastFirst[1], LastFirst[0]\n",
    "#Remove comma from Name column, so that this can be saved as a CSV ----- Must happen after splitting Name into two cols!!\n",
    "results['Name'] = results['Name'].str.replace(r'(\\,)', \"\")\n",
    "#Replace non-standard '–' with NaN for missing vals\n",
    "results = results.replace('–', np.nan)\n",
    "results = results.replace('', np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "results =  results.astype({\"Place (Overall)\": 'Int64',\n",
    "                           \"Place (Gender)\": 'Int64',\n",
    "                           \"Place (Category)\": 'Int64',\n",
    "                           \"Name\": str,\n",
    "                           \"Sex\": str,\n",
    "                           \"Club\": str,\n",
    "                           \"Running Number\": 'Int64',\n",
    "                           \"Category\": str,\n",
    "                           \"Year\": 'Int64'})\n",
    "results['Finish'] = pd.to_timedelta(results['Finish'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      Place (Overall)  Place (Gender)  Place (Category)  \\\n",
       "0                   1               1                 1   \n",
       "1                   2               2                 2   \n",
       "2                   3               3                 3   \n",
       "3                   4               4                 4   \n",
       "4                   5               5                 5   \n",
       "...               ...             ...               ...   \n",
       "996             21445            6469               242   \n",
       "997             42539           17767              2943   \n",
       "998             10669            2574                 3   \n",
       "999             11000            2676               542   \n",
       "1000            11132            2728               413   \n",
       "\n",
       "                             Name Sex  \\\n",
       "0                 Mutai Emmanuel    M   \n",
       "1                     Lel Martin    M   \n",
       "2                  Makau Patrick    M   \n",
       "3      Dos Santos Marlison Gomes    M   \n",
       "4                 Kebede Tsegaye    M   \n",
       "...                           ...  ..   \n",
       "996                 Barrow Susan    W   \n",
       "997                 Barrow Tracy    W   \n",
       "998            Barrow-Green June    W   \n",
       "999     Barrow-Williams Samantha    W   \n",
       "1000         Barrowcliffe Janine    W   \n",
       "\n",
       "                                             Club  Running Number Category  \\\n",
       "0                                             nan               8    18-39   \n",
       "1                                             nan              27    18-39   \n",
       "2                                             nan               3    18-39   \n",
       "3                                             nan              13    18-39   \n",
       "4                                             nan               1    18-39   \n",
       "...                                           ...             ...      ...   \n",
       "996                  Rutland Running & Triathlon            23582    55-59   \n",
       "997                                           nan           12302    40-44   \n",
       "998   Victoria Park Harriers and Tower Hamlets AC           33934    65-69   \n",
       "999                                           nan           48131    40-44   \n",
       "1000                                          nan           28801    45-49   \n",
       "\n",
       "              Finish  Year Country         FirstName         LastName  \n",
       "0    0 days 02:04:40  2011     KEN         Emmanuel             Mutai  \n",
       "1    0 days 02:05:45  2011     KEN           Martin               Lel  \n",
       "2    0 days 02:05:45  2011     KEN          Patrick             Makau  \n",
       "3    0 days 02:06:34  2011     BRA   Marlison Gomes        Dos Santos  \n",
       "4    0 days 02:07:48  2011     ETH          Tsegaye            Kebede  \n",
       "...              ...   ...     ...               ...              ...  \n",
       "996  0 days 04:25:20  2019     GBR            Susan            Barrow  \n",
       "997  0 days 08:18:53  2019     GBR            Tracy            Barrow  \n",
       "998  0 days 03:46:34  2019     GBR             June      Barrow-Green  \n",
       "999  0 days 03:47:55  2019     GBR         Samantha   Barrow-Williams  \n",
       "1000 0 days 03:48:29  2019     GBR           Janine      Barrowcliffe  \n",
       "\n",
       "[18000 rows x 13 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Place (Overall)</th>\n      <th>Place (Gender)</th>\n      <th>Place (Category)</th>\n      <th>Name</th>\n      <th>Sex</th>\n      <th>Club</th>\n      <th>Running Number</th>\n      <th>Category</th>\n      <th>Finish</th>\n      <th>Year</th>\n      <th>Country</th>\n      <th>FirstName</th>\n      <th>LastName</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Mutai Emmanuel</td>\n      <td>M</td>\n      <td>nan</td>\n      <td>8</td>\n      <td>18-39</td>\n      <td>0 days 02:04:40</td>\n      <td>2011</td>\n      <td>KEN</td>\n      <td>Emmanuel</td>\n      <td>Mutai</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>Lel Martin</td>\n      <td>M</td>\n      <td>nan</td>\n      <td>27</td>\n      <td>18-39</td>\n      <td>0 days 02:05:45</td>\n      <td>2011</td>\n      <td>KEN</td>\n      <td>Martin</td>\n      <td>Lel</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>Makau Patrick</td>\n      <td>M</td>\n      <td>nan</td>\n      <td>3</td>\n      <td>18-39</td>\n      <td>0 days 02:05:45</td>\n      <td>2011</td>\n      <td>KEN</td>\n      <td>Patrick</td>\n      <td>Makau</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>4</td>\n      <td>4</td>\n      <td>Dos Santos Marlison Gomes</td>\n      <td>M</td>\n      <td>nan</td>\n      <td>13</td>\n      <td>18-39</td>\n      <td>0 days 02:06:34</td>\n      <td>2011</td>\n      <td>BRA</td>\n      <td>Marlison Gomes</td>\n      <td>Dos Santos</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>5</td>\n      <td>5</td>\n      <td>Kebede Tsegaye</td>\n      <td>M</td>\n      <td>nan</td>\n      <td>1</td>\n      <td>18-39</td>\n      <td>0 days 02:07:48</td>\n      <td>2011</td>\n      <td>ETH</td>\n      <td>Tsegaye</td>\n      <td>Kebede</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>996</th>\n      <td>21445</td>\n      <td>6469</td>\n      <td>242</td>\n      <td>Barrow Susan</td>\n      <td>W</td>\n      <td>Rutland Running &amp; Triathlon</td>\n      <td>23582</td>\n      <td>55-59</td>\n      <td>0 days 04:25:20</td>\n      <td>2019</td>\n      <td>GBR</td>\n      <td>Susan</td>\n      <td>Barrow</td>\n    </tr>\n    <tr>\n      <th>997</th>\n      <td>42539</td>\n      <td>17767</td>\n      <td>2943</td>\n      <td>Barrow Tracy</td>\n      <td>W</td>\n      <td>nan</td>\n      <td>12302</td>\n      <td>40-44</td>\n      <td>0 days 08:18:53</td>\n      <td>2019</td>\n      <td>GBR</td>\n      <td>Tracy</td>\n      <td>Barrow</td>\n    </tr>\n    <tr>\n      <th>998</th>\n      <td>10669</td>\n      <td>2574</td>\n      <td>3</td>\n      <td>Barrow-Green June</td>\n      <td>W</td>\n      <td>Victoria Park Harriers and Tower Hamlets AC</td>\n      <td>33934</td>\n      <td>65-69</td>\n      <td>0 days 03:46:34</td>\n      <td>2019</td>\n      <td>GBR</td>\n      <td>June</td>\n      <td>Barrow-Green</td>\n    </tr>\n    <tr>\n      <th>999</th>\n      <td>11000</td>\n      <td>2676</td>\n      <td>542</td>\n      <td>Barrow-Williams Samantha</td>\n      <td>W</td>\n      <td>nan</td>\n      <td>48131</td>\n      <td>40-44</td>\n      <td>0 days 03:47:55</td>\n      <td>2019</td>\n      <td>GBR</td>\n      <td>Samantha</td>\n      <td>Barrow-Williams</td>\n    </tr>\n    <tr>\n      <th>1000</th>\n      <td>11132</td>\n      <td>2728</td>\n      <td>413</td>\n      <td>Barrowcliffe Janine</td>\n      <td>W</td>\n      <td>nan</td>\n      <td>28801</td>\n      <td>45-49</td>\n      <td>0 days 03:48:29</td>\n      <td>2019</td>\n      <td>GBR</td>\n      <td>Janine</td>\n      <td>Barrowcliffe</td>\n    </tr>\n  </tbody>\n</table>\n<p>18000 rows × 13 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "source": [
    "# Let's see what we've got\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And quickly save them in a csv\n",
    "results.to_csv(r'C:\\Users\\michael.walshe\\Documents\\Python Projects\\scrape_london_marathon\\London_Marathon_Big.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Profiling function to find bottlenecks, need to speed up parser more???\n",
    "# url = 'https://results.virginmoneylondonmarathon.com/2019/?page=1&event=ALL&'+ \\\n",
    "#       'num_results=1000&pid=search&pidp=results_nav&search%5Bsex%5D=M&search%5Bage_'+ \\\n",
    "#        'class%5D=%25&search%5Bnation%5D=%25&search_sort=name'\n",
    "\n",
    "# %lprun -f get_results_new get_results_new(url, \"M\", 2019)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python385jvsc74a57bd00188e1d2bc53a9294aae56bf1ea31698e906b60a882ff91489addc94996f1fb7",
   "display_name": "Python 3.8.5 64-bit ('testenv': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}