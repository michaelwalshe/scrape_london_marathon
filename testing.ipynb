{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import lxml\n",
    "from bs4 import BeautifulSoup, SoupStrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results_new(url1, url2, url3, pages, sex, year):\n",
    "    #Function to scrape modern virgin london marathon results page (2020 and 2019)\n",
    "    #Set up empty dataframe for results\n",
    "    results = pd.DataFrame()\n",
    "    \n",
    "    #Loop through all pages to be scraped\n",
    "    for i in range(pages+1):\n",
    "        #Use requests to get content from site\n",
    "        site=requests.get(url1+str(i)+url2+sex+url3).content\n",
    "        #Soup strainer restricts content to sped up soup\n",
    "        strainer = SoupStrainer(id=\"cbox-main\")\n",
    "        #Parse the html\n",
    "        soup = BeautifulSoup(site,'lxml', parse_only=strainer)\n",
    "        \n",
    "        #Loop through each row and column to create a list of cells\n",
    "        my_table = []\n",
    "        for row in soup.find_all(class_='list-group-item'):\n",
    "            row_data = []\n",
    "            for cell in row.find_all(class_='list-field'):\n",
    "                row_data.append(cell.text)\n",
    "            \n",
    "            #If the row isn't empty, then create a dict of the row to create datafram from\n",
    "            if(len(row_data) > 0):\n",
    "                data_item = {\"Place (Overall)\": row_data[0],\n",
    "                             \"Place (Gender)\": row_data[1],\n",
    "                             \"Place (Category)\": row_data[2],\n",
    "                             \"Name\": row_data[3],\n",
    "                             \"Sex\": sex,\n",
    "                             \"Club\": row_data[4],\n",
    "                             \"Running Number\": row_data[5],\n",
    "                             \"Category\": row_data[6],\n",
    "                             \"Finish\": row_data[7]\n",
    "                }\n",
    "                my_table.append(data_item)\n",
    "        \n",
    "        #Strip table header\n",
    "        df = pd.DataFrame(my_table).iloc[1:]\n",
    "        \n",
    "        #Append to results\n",
    "        results = results.append(df)\n",
    "    \n",
    "    return results\n",
    "\n",
    "def get_results_old(url1, url2, pages, sex, year):\n",
    "    #Function to scrape old virgin london marathon results page (2014 to 2018)\n",
    "    #Set up empty dataframe for results\n",
    "    results = pd.DataFrame()\n",
    "\n",
    "    #Loop through all pages to be scraped\n",
    "    for i in range(pages+1):\n",
    "        #Use requests to get content from site\n",
    "        site=requests.get(url1+str(i)+url2+sex).content\n",
    "        #Soup strainer restricts content to sped up soup\n",
    "        strainer = SoupStrainer('tbody')\n",
    "        #Parse the html\n",
    "        #soup = BeautifulSoup(site,'lxml', parse_only=strainer)\n",
    "        soup = BeautifulSoup(site,'lxml')\n",
    "\n",
    "        my_table = []\n",
    "        for row in soup.find_all('tr'):\n",
    "            row_data = []\n",
    "            for cell in row.find_all('td'):\n",
    "                #Check if cell has alt text, if so use that as data\n",
    "                alt_text = cell.find('span')\n",
    "                if alt_text != None:\n",
    "                    cell = alt_text['title']\n",
    "                else:\n",
    "                    cell = cell.text\n",
    "                row_data.append(cell)\n",
    "                \n",
    "            #If the row isn't empty, then create a dict of the row to create datafram from\n",
    "            if(len(row_data) > 0):\n",
    "                data_item = {\"Place (Overall)\": row_data[0],\n",
    "                                \"Place (Gender)\": row_data[1],\n",
    "                                \"Place (Category)\": row_data[2],\n",
    "                                \"Name\": row_data[3],\n",
    "                                \"Sex\": sex,\n",
    "                                \"Club\": row_data[4],\n",
    "                                \"Running Number\": row_data[5],\n",
    "                                \"Category\": row_data[6],\n",
    "                                \"Finish\": row_data[8],\n",
    "                                \"Year\": year\n",
    "                }\n",
    "                my_table.append(data_item)\n",
    "\n",
    "        #Strip table header\n",
    "        df = pd.DataFrame(my_table)\n",
    "\n",
    "        #Append to results\n",
    "        results = results.append(df)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Get results for recent 2020\n",
    "# url1='https://results.virginmoneylondonmarathon.com/2020/?page='\n",
    "# url2='&event=ALL&num_results=1000&pid=search&pidp=results_nav&search%5Bsex%5D='\n",
    "# url3='&search%5Bage_class%5D=%25&search%5Bnation%5D=%25&search_sort=name'\n",
    "# #Get results for men, 22 pages of results <-There is no search option for other gender/sex\n",
    "# mens_2020 = get_results_new(url1, url2, url3, pages=22, sex='M', year=2020)\n",
    "# #Get results for women, 22 pages of results\n",
    "# womens_2020 = get_results_new(url1, url2, url3, pages=22, sex='W', year=2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Get results for recent 2019\n",
    "# url1='https://results.virginmoneylondonmarathon.com/2019/?page='\n",
    "# url2='&event=ALL&num_results=1000&pid=search&pidp=results_nav&search%5Bsex%5D='\n",
    "# url3='&search%5Bage_class%5D=%25&search%5Bnation%5D=%25&search_sort=name'\n",
    "# #Get results for men, 22 pages of results <-There is no search option for other gender/sex\n",
    "# mens_2019 = get_results_new(url1, url2, url3, pages=25, sex='M')\n",
    "# #Get results for women, 22 pages of results\n",
    "# womens_2019 = get_results_new(url1, url2, url3, pages=18, sex='W')\n",
    "\n",
    "# # Concatenate results\n",
    "# results_2019_2020 = pd.concat([mens_2020, womens_2020, mens_2019, womens_2019])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get results for 2014 to 2018, searches for number of pages\n",
    "# results_2014_2018 = pd.DataFrame()\n",
    "# for year in range(2014, 2019):\n",
    "#     url1='https://results.virginmoneylondonmarathon.com/'+str(year)+'/?page='\n",
    "#     url2='&event=MAS&num_results=1000&pid=list&search%5Bage_class%5D=%25&search%5Bsex%5D='\n",
    "    \n",
    "#     site_m=requests.get(url1+'1'+url2+'M').text\n",
    "#     site_w=requests.get(url1+'1'+url2+'W').text\n",
    "#     soup_m = BeautifulSoup(site_m,'lxml')\n",
    "#     soup_w = BeautifulSoup(site_w,'lxml')\n",
    "\n",
    "#     m_pages = int(soup_m.find(class_='pages').text[-4:-2])\n",
    "#     w_pages = int(soup_w.find(class_='pages').text[-4:-2])\n",
    "    \n",
    "    \n",
    "#     mens = get_results_2014_2018(url1, url2, pages=m_pages, sex='M', year=year)\n",
    "#     womens = get_results_2014_2018(url1, url2, pages=w_pages, sex='W', year=year)\n",
    "    \n",
    "#     results_2014_2018 = results_2014_2018.append(pd.concat([mens, womens]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Get results for 2010 to 2013\n",
    "# results_2010_2013 = pd.DataFrame()\n",
    "# for year in range(2010, 2014):\n",
    "#     url1='https://results.virginmoneylondonmarathon.com/'+str(year)+'/index.php?page='\n",
    "#     url2='&event=MAS&num_results=1000&pid=search&search%5Bsex%5D='\n",
    "#     site_m=requests.get(url1+'1'+url2+'M').text\n",
    "#     site_w=requests.get(url1+'1'+url2+'W').text\n",
    "#     soup_m = BeautifulSoup(site_m,'lxml')\n",
    "#     soup_w = BeautifulSoup(site_w,'lxml')\n",
    "\n",
    "#     m_pages = int(soup_m.find(class_='pages').text[-4:-2])\n",
    "#     w_pages = int(soup_w.find(class_='pages').text[-4:-2])\n",
    "    \n",
    "    \n",
    "#     mens = get_results_old(url1, url2, pages=m_pages, sex='M', year=year)\n",
    "#     womens = get_results_old(url1, url2, pages=w_pages, sex='W', year=year)\n",
    "    \n",
    "#     results_2010_2013 = results_2010_2013.append(pd.concat([mens, womens]))\n",
    "\n",
    "# london_marathon_results = pd.concat(results_2019_2020, results_2014_2018, results_2010_2013])\n",
    "url1='https://results.virginmoneylondonmarathon.com/'+str(2013)+'/index.php?page='\n",
    "url2='&event=MAS&num_results=10&pid=search&search%5Bsex%5D='\n",
    "\n",
    "mens = get_results_old(url1, url2, pages=1, sex='M', year=2011)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mens.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "url1='https://results.virginmoneylondonmarathon.com/'+str(2014)+'/?page='\n",
    "url2='&event=MAS&num_results=100&pid=search&search%5Bsex%5D='\n",
    "year = 2014\n",
    "sex = 'M'\n",
    "site=requests.get(url1+str(1)+url2+sex).content\n",
    "#Soup strainer restricts content to sped up soup\n",
    "strainer = SoupStrainer('tbody')\n",
    "#Parse the html\n",
    "#soup = BeautifulSoup(site,'lxml', parse_only=strainer)\n",
    "soup = BeautifulSoup(site,'lxml', parse_only=strainer)\n",
    "\n",
    "my_table = []\n",
    "for row in soup.find_all('tr'):\n",
    "    row_data = []\n",
    "    for cell in row.find_all('td'):\n",
    "        #Check if cell has alt text, if so use that as data\n",
    "        alt_text = cell.find('span')\n",
    "        if alt_text != None:\n",
    "            cell = alt_text['title']\n",
    "        else:\n",
    "            cell = cell.text\n",
    "        row_data.append(cell)\n",
    "        \n",
    "    #If the row isn't empty, then create a dict of the row to create datafram from\n",
    "    if(len(row_data) > 0):\n",
    "        data_item = {\"Place (Overall)\": row_data[0],\n",
    "                        \"Place (Gender)\": row_data[1],\n",
    "                        \"Place (Category)\": row_data[2],\n",
    "                        \"Name\": row_data[3],\n",
    "                        \"Sex\": sex,\n",
    "                        \"Club\": row_data[4],\n",
    "                        \"Running Number\": row_data[6],\n",
    "                        \"Category\": row_data[7],\n",
    "                        \"Finish\": row_data[9],\n",
    "                        \"Year\": year\n",
    "        }\n",
    "        my_table.append(data_item)\n",
    "\n",
    "#Strip table header\n",
    "df = pd.DataFrame(my_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(my_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Some quick data cleaning\n",
    "london_marathon_results['Club'] = london_marathon_results['Club'].str.replace(\"Club\", \"\", regex=False)\n",
    "london_marathon_results['Running Number'] = london_marathon_results['Running Number'].str.replace(\"Running Number\", \"\", regex=False)\n",
    "london_marathon_results['Category'] = london_marathon_results['Category'].str.replace(\"Category\", \"\", regex=False)\n",
    "london_marathon_results['Finish'] = london_marathon_results['Finish'].str.replace(\"Finish\", \"\", regex=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see what we've got\n",
    "london_marathon_results.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And quickly save them in a csv\n",
    "london_marathon_results.to_csv(r'C:\\Users\\michael.walshe\\Documents\\Python and CAS\\London_Marathon.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python385jvsc74a57bd00188e1d2bc53a9294aae56bf1ea31698e906b60a882ff91489addc94996f1fb7",
   "display_name": "Python 3.8.5 64-bit ('testenv': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}