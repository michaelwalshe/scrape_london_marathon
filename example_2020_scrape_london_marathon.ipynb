{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "# Connect to website to be scraped, and get all html\n",
    "url1='https://results.virginmoneylondonmarathon.com/2020/?page='\n",
    "url2='&event=ALL&num_results=1000&pid=search&pidp=results_nav&search%5Bsex%5D='\n",
    "url3='&search%5Bage_class%5D=%25&search%5Bnation%5D=%25&search_sort=name'\n",
    "\n",
    "#Get results for men, 878 pages of results <-There is no search option for other gender/sex\n",
    "mens_results = pd.DataFrame()\n",
    "for i in range(22)\n",
    "    sex='M'\n",
    "    website_url=requests.get(url1+str(i)+url2+sex+url3).text\n",
    "    soup = BeautifulSoup(website_url,'lxml')\n",
    "\n",
    "    fields = soup.find(class_='section-main')\n",
    "\n",
    "    my_table = []\n",
    "    for row in fields.findAll(class_='list-group-item'):\n",
    "        row_data = []\n",
    "        for cell in row.findAll(class_='list-field'):\n",
    "            row_data.append(cell.text)\n",
    "\n",
    "        if(len(row_data) > 0):\n",
    "            data_item = {\"Place (Overall)\": row_data[0],\n",
    "                         \"Place (Gender)\": row_data[1],\n",
    "                         \"Place (Category)\": row_data[2],\n",
    "                         \"Name\": row_data[3],\n",
    "                         \"Sex\": sex,\n",
    "                         \"Club\": row_data[4],\n",
    "                         \"Running Number\": row_data[5],\n",
    "                         \"Category\": row_data[6],\n",
    "                         \"Finish\": row_data[7],\n",
    "            }\n",
    "            print(row_data)\n",
    "            my_table.append(data_item)\n",
    "    df = pd.DataFrame(my_table).iloc[1:]\n",
    "    \n",
    "    mens_results = mens_results.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get results for women\n",
    "womens_results = pd.DataFrame()\n",
    "for i in range(22)\n",
    "    sex='F'\n",
    "    website_url=requests.get(url1+str(i)+url2+sex+url3).text\n",
    "    soup = BeautifulSoup(website_url,'lxml')\n",
    "\n",
    "    fields = soup.find(class_='section-main')\n",
    "\n",
    "    my_table = []\n",
    "    for row in fields.findAll(class_='list-group-item'):\n",
    "        row_data = []\n",
    "        for cell in row.findAll(class_='list-field'):\n",
    "            row_data.append(cell.text)\n",
    "\n",
    "        if(len(row_data) > 0):\n",
    "            data_item = {\"Place (Overall)\": row_data[0],\n",
    "                         \"Place (Gender)\": row_data[1],\n",
    "                         \"Place (Category)\": row_data[2],\n",
    "                         \"Name\": row_data[3],\n",
    "                         \"Sex\": sex,\n",
    "                         \"Club\": row_data[4],\n",
    "                         \"Running Number\": row_data[5],\n",
    "                         \"Category\": row_data[6],\n",
    "                         \"Finish\": row_data[7],\n",
    "            }\n",
    "            my_table.append(data_item)\n",
    "\n",
    "    df = pd.DataFrame(my_table).iloc[1:]\n",
    "    \n",
    "    womens_results = womens_results.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate results\n",
    "results = pd.concat([mens_results, womens_results])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Some quick data cleaning\n",
    "#Remove leftover titles\n",
    "results['Club'] = results['Club'].str.replace(\"Club\", \"\", regex=False)\n",
    "results['Running Number'] = results['Running Number'].str.replace(\"Running Number\", \"\", regex=False)\n",
    "results['Category'] = results['Category'].str.replace(\"Category\", \"\", regex=False)\n",
    "results['Finish'] = results['Finish'].str.replace(\"Finish\", \"\", regex=False)\n",
    "\n",
    "#Extract country groups, like (USA), from Name group\n",
    "results['Country'] = results['Name'].str.extract(r'(\\([A-Z]{3,}\\))')\n",
    "#Remove brackets in country\n",
    "results['Country'] = results['Country'].str.replace(r'\\(|\\)', \"\", regex=True)\n",
    "#Remove country group from name column\n",
    "results['Name'] = results['Name'].str.replace(r'(\\([A-Z]{3}\\))', \"\", regex=True)\n",
    "\n",
    "#Split first/lastname into new columns\n",
    "LastFirst = results['Name'].str.split(pat=\",\", n=1, expand=True) \n",
    "results['FirstName'], results['LastName'] = LastFirst[1], LastFirst[0]\n",
    "#Remove comma from Name column, so that this can be saved as a CSV ----- Must happen after splitting Name into two cols!!\n",
    "results['Name'] = results['Name'].str.replace(r'(\\,)', \"\", regex=True)\n",
    "#Replace non-standard '–' with NaN for missing vals\n",
    "results = results.replace('–', np.nan)\n",
    "results = results.replace('DSQ', np.nan)\n",
    "results = results.replace('', np.nan)\n",
    "\n",
    "#Delete odd race number row - table description not actual data\n",
    "results = results.loc[(results['Running Number'] != 'RM9999') & (results['Running Number'] != 'RF9999')]\n",
    "\n",
    "#Set data types\n",
    "results =  results.astype({\"Place (Overall)\": 'float64',\n",
    "                           \"Place (Gender)\": 'float64',\n",
    "                           \"Place (Category)\": 'float64',\n",
    "                           \"Name\": str,\n",
    "                           \"Sex\": str,\n",
    "                           \"Club\": str,\n",
    "                           \"Running Number\": str,\n",
    "                           \"Category\": 'category',\n",
    "                           \"Country\": str,\n",
    "                           \"FirstName\": str,\n",
    "                           \"LastName\": str})\n",
    "# Due to an irritating bug with converting objects to Int64, needed to first convert to float and then to int\n",
    "results =  results.astype({\"Place (Overall)\": 'Int64',\n",
    "                           \"Place (Gender)\": 'Int64',\n",
    "                           \"Place (Category)\": 'Int64'})\n",
    "results['Finish'] = pd.to_timedelta(results['Finish'])\n",
    "results['Finish (Total Seconds)'] = results['Finish'].dt.total_seconds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And quickly save them in a csv\n",
    "results.to_csv(r'C:\\Users\\michael.walshe\\Documents\\Python Projects\\Scraping_London_Marathon_Project\\London_2020.csv', index=False, header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python388jvsc74a57bd0141990a20678273a854e9f710d7438d35c6e8d8fa786e498058914c4bbad7160",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}